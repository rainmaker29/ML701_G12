{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-10-24T15:32:19.916013Z",
     "iopub.status.busy": "2022-10-24T15:32:19.915154Z",
     "iopub.status.idle": "2022-10-24T15:34:18.415970Z",
     "shell.execute_reply": "2022-10-24T15:34:18.414979Z",
     "shell.execute_reply.started": "2022-10-24T15:32:19.915965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.6.11-py3-none-any.whl (548 kB)\n",
      "\u001b[K     |████████████████████████████████| 548 kB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.7.0\n",
      "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 776.7 MB 2.5 kB/s s eta 0:00:01.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torchvision==0.8.1\n",
      "  Downloading torchvision-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (12.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.7 MB 41.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0) (0.18.2)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0) (0.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.7.0) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.8.1) (8.2.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.7/site-packages (from timm) (0.0.17)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (21.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (3.0.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (4.62.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub->timm) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub->timm) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub->timm) (3.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub->timm) (4.0.0)\n",
      "Installing collected packages: torch, torchvision, timm\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1+cpu\n",
      "    Uninstalling torch-1.7.1+cpu:\n",
      "      Successfully uninstalled torch-1.7.1+cpu\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.8.2+cpu\n",
      "    Uninstalling torchvision-0.8.2+cpu:\n",
      "      Successfully uninstalled torchvision-0.8.2+cpu\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.8.1 requires torch==1.7.1, but you have torch 1.7.0 which is incompatible.\n",
      "torchaudio 0.7.2 requires torch==1.7.1, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
      "Successfully installed timm-0.6.11 torch-1.7.0 torchvision-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  6034  100  6034    0     0  34808      0 --:--:-- --:--:-- --:--:-- 34878\n",
      "Updating... This may take around 2 minutes.\n",
      "Updating TPU runtime to pytorch-dev20200515 ...\n",
      "Found existing installation: torch 1.7.0\n",
      "Uninstalling torch-1.7.0:\n",
      "  Successfully uninstalled torch-1.7.0\n",
      "Found existing installation: torchvision 0.8.1\n",
      "Uninstalling torchvision-0.8.1:\n",
      "  Successfully uninstalled torchvision-0.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Copying gs://tpu-pytorch/wheels/torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
      "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
      "Operation completed over 1 objects/91.0 MiB.                                     \n",
      "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
      "\\ [1 files][119.5 MiB/119.5 MiB]                                                \n",
      "Operation completed over 1 objects/119.5 MiB.                                    \n",
      "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl...\n",
      "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
      "Operation completed over 1 objects/2.3 MiB.                                      \n",
      "Processing ./torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (1.19.5)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch==nightly+20200515) (0.18.2)\n",
      "Installing collected packages: torch\n",
      "Done updating TPU runtime\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "timm 0.6.11 requires torchvision, which is not installed.\n",
      "fastai 2.2.7 requires torchvision<0.9,>=0.8, which is not installed.\n",
      "easyocr 1.4.1 requires torchvision>=0.5, which is not installed.\n",
      "allennlp 2.7.0 requires torchvision<0.11.0,>=0.8.1, which is not installed.\n",
      "torchtext 0.8.1 requires torch==1.7.1, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "torchaudio 0.7.2 requires torch==1.7.1, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "timm 0.6.11 requires torch>=1.7, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "pytorch-lightning 1.4.4 requires torch>=1.6, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "kornia 0.5.8 requires torch>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "fairscale 0.4.0 requires torch>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "allennlp 2.7.0 requires torch<1.10.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\u001b[0m\n",
      "Successfully installed torch-1.6.0a0+bf2bbd9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Processing ./torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "Installing collected packages: torch-xla\n",
      "Successfully installed torch-xla-1.6+2b2085a\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Processing ./torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (8.2.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.6.0a0+bf2bbd9)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==nightly+20200515) (1.19.5)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from torch->torchvision==nightly+20200515) (0.18.2)\n",
      "Installing collected packages: torchvision\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "timm 0.6.11 requires torch>=1.7, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "fastai 2.2.7 requires torch<1.8,>=1.7.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "fastai 2.2.7 requires torchvision<0.9,>=0.8, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\n",
      "allennlp 2.7.0 requires torch<1.10.0,>=1.6.0, but you have torch 1.6.0a0+bf2bbd9 which is incompatible.\n",
      "allennlp 2.7.0 requires torchvision<0.11.0,>=0.8.1, but you have torchvision 0.7.0a0+a6073f0 which is incompatible.\u001b[0m\n",
      "Successfully installed torchvision-0.7.0a0+a6073f0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  libomp5\n",
      "0 upgraded, 1 newly installed, 0 to remove and 18 not upgraded.\n",
      "Need to get 234 kB of archives.\n",
      "After this operation, 774 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
      "Fetched 234 kB in 0s (737 kB/s) \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package libomp5:amd64.\n",
      "(Reading database ... 106894 files and directories currently installed.)\n",
      "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
      "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
      "Setting up libomp5:amd64 (5.0.1-1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\n"
     ]
    }
   ],
   "source": [
    "!pip install timm torch==1.7.0 torchvision==0.8.1\n",
    "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "!python pytorch-xla-env-setup.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:18.417990Z",
     "iopub.status.busy": "2022-10-24T15:34:18.417712Z",
     "iopub.status.idle": "2022-10-24T15:34:21.442406Z",
     "shell.execute_reply": "2022-10-24T15:34:21.441510Z",
     "shell.execute_reply.started": "2022-10-24T15:34:18.417956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('__call__', <function LevelMapper.__call__ at 0x7fe8565b1170>), ('__init__', <function LevelMapper.__init__ at 0x7fe8565b10e0>)]\n",
      "[('__call__', <function BalancedPositiveNegativeSampler.__call__ at 0x7fe88165ba70>), ('__init__', <function BalancedPositiveNegativeSampler.__init__ at 0x7fe88165b9e0>)]\n",
      "[('__init__', <function BoxCoder.__init__ at 0x7fe88166b290>), ('decode', <function BoxCoder.decode at 0x7fe88166b440>), ('decode_single', <function BoxCoder.decode_single at 0x7fe88166b4d0>), ('encode', <function BoxCoder.encode at 0x7fe88166b320>), ('encode_single', <function BoxCoder.encode_single at 0x7fe88166b3b0>)]\n",
      "[('__call__', <function Matcher.__call__ at 0x7fe88166b5f0>), ('__init__', <function Matcher.__init__ at 0x7fe881660f80>), ('set_low_quality_matches_', <function Matcher.set_low_quality_matches_ at 0x7fe88166b170>)]\n",
      "[('__init__', <function ImageList.__init__ at 0x7fe88166b0e0>), ('to', <function ImageList.to at 0x7fe88166b710>)]\n",
      "[('__init__', <function Timebase.__init__ at 0x7fe8814da5f0>)]\n",
      "[('__init__', <function VideoMetaData.__init__ at 0x7fe8814dd680>)]\n",
      "[('__call__', <function SpaceToDepthJit.__call__ at 0x7fe843de5050>)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "\n",
    "import timm\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.444314Z",
     "iopub.status.busy": "2022-10-24T15:34:21.444046Z",
     "iopub.status.idle": "2022-10-24T15:34:21.450176Z",
     "shell.execute_reply": "2022-10-24T15:34:21.448654Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.444283Z"
    }
   },
   "outputs": [],
   "source": [
    "# For parallelization in TPUs\n",
    "os.environ[\"XLA_USE_BF16\"] = \"1\"\n",
    "os.environ[\"XLA_TENSOR_ALLOCATOR_MAXSIZE\"] = \"100000000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.452795Z",
     "iopub.status.busy": "2022-10-24T15:34:21.452346Z",
     "iopub.status.idle": "2022-10-24T15:34:21.466857Z",
     "shell.execute_reply": "2022-10-24T15:34:21.465949Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.452763Z"
    }
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Seeds basic parameters for reproductibility of results\n",
    "    \n",
    "    Arguments:\n",
    "        seed {int} -- Number of the seed\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.468672Z",
     "iopub.status.busy": "2022-10-24T15:34:21.468387Z",
     "iopub.status.idle": "2022-10-24T15:34:21.527532Z",
     "shell.execute_reply": "2022-10-24T15:34:21.526863Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.468641Z"
    }
   },
   "outputs": [],
   "source": [
    "#make train, test sets\n",
    "from sklearn import preprocessing\n",
    "\n",
    "DATA_PATH = \"../input/sdss-images/data.csv\"\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['class'] = le.fit_transform(df['class'])\n",
    "\n",
    "train,val = train_test_split(df,test_size=0.2,random_state=2022)\n",
    "train = train.reset_index().drop(['index'],axis=1)\n",
    "val = val.reset_index().drop(['index'],axis=1)\n",
    "val,test= train_test_split(val,test_size=0.5,random_state=2022)\n",
    "val = val.reset_index().drop(['index'],axis=1)\n",
    "test = test.reset_index().drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.529169Z",
     "iopub.status.busy": "2022-10-24T15:34:21.528590Z",
     "iopub.status.idle": "2022-10-24T15:34:21.537992Z",
     "shell.execute_reply": "2022-10-24T15:34:21.536990Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.529135Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['GALAXY', 'QSO', 'STAR'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.539484Z",
     "iopub.status.busy": "2022-10-24T15:34:21.539244Z",
     "iopub.status.idle": "2022-10-24T15:34:21.562710Z",
     "shell.execute_reply": "2022-10-24T15:34:21.561950Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.539456Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>image_5516.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>image_1255.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class           image\n",
       "0      0  image_5516.jpg\n",
       "1      1  image_1255.jpg"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:21.564986Z",
     "iopub.status.busy": "2022-10-24T15:34:21.564119Z",
     "iopub.status.idle": "2022-10-24T15:34:23.754740Z",
     "shell.execute_reply": "2022-10-24T15:34:23.753433Z",
     "shell.execute_reply.started": "2022-10-24T15:34:21.564926Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir images\n",
    "!mkdir images/val images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:34:23.757597Z",
     "iopub.status.busy": "2022-10-24T15:34:23.757190Z",
     "iopub.status.idle": "2022-10-24T15:35:01.909323Z",
     "shell.execute_reply": "2022-10-24T15:35:01.908138Z",
     "shell.execute_reply.started": "2022-10-24T15:34:23.757531Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for img in train['image']:\n",
    "    shutil.copy(\"../input/sdss-images/images (1)/images/\"+img,\"./images/train/\"+img)\n",
    "    \n",
    "for img in val['image']:\n",
    "    shutil.copy(\"../input/sdss-images/images (1)/images/\"+img,\"./images/val/\"+img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.912425Z",
     "iopub.status.busy": "2022-10-24T15:35:01.912162Z",
     "iopub.status.idle": "2022-10-24T15:35:01.921006Z",
     "shell.execute_reply": "2022-10-24T15:35:01.920015Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.912394Z"
    }
   },
   "outputs": [],
   "source": [
    "# general global variables\n",
    "DATA_PATH = \"../input/sdss-images/data.csv\"\n",
    "TRAIN_PATH = \"./images/train\"\n",
    "TEST_PATH = \"./images/val\"\n",
    "MODEL_PATH = (\n",
    "    \"../input/vit-base-models-pretrained-pytorch/jx_vit_base_p16_224-80ecf9dd.pth\"\n",
    ")\n",
    "\n",
    "# model specific global variables\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32 #32\n",
    "LR = 2e-05\n",
    "GAMMA = 0.7\n",
    "N_EPOCHS = 10\n",
    "wandb_args = {\"learning_rate\": LR, \"epochs\": N_EPOCHS, \"batch_size\": BATCH_SIZE,\"gamma\":GAMMA,\"img_size\":IMG_SIZE,\"project\":\"ViT SDSS\",\"name\":\"Default aug\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.922705Z",
     "iopub.status.busy": "2022-10-24T15:35:01.922388Z",
     "iopub.status.idle": "2022-10-24T15:35:01.932431Z",
     "shell.execute_reply": "2022-10-24T15:35:01.931484Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.922673Z"
    }
   },
   "outputs": [],
   "source": [
    "class SDSSDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, mode=\"train\", transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        self.mode = mode\n",
    "        self.data_dir = \"./images/train\" if mode == \"train\" else \"./images/val\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label,img_name = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.934000Z",
     "iopub.status.busy": "2022-10-24T15:35:01.933657Z",
     "iopub.status.idle": "2022-10-24T15:35:01.946196Z",
     "shell.execute_reply": "2022-10-24T15:35:01.945246Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.933972Z"
    }
   },
   "outputs": [],
   "source": [
    "# create image augmentations\n",
    "transforms_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.950610Z",
     "iopub.status.busy": "2022-10-24T15:35:01.949606Z",
     "iopub.status.idle": "2022-10-24T15:35:01.970351Z",
     "shell.execute_reply": "2022-10-24T15:35:01.969312Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.950564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Vision Transformer Models: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Available Vision Transformer Models: \")\n",
    "timm.list_models(\"vit*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.972092Z",
     "iopub.status.busy": "2022-10-24T15:35:01.971827Z",
     "iopub.status.idle": "2022-10-24T15:35:01.990917Z",
     "shell.execute_reply": "2022-10-24T15:35:01.989859Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.972064Z"
    }
   },
   "outputs": [],
   "source": [
    "class ViTBase16(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained=False):\n",
    "\n",
    "        super(ViTBase16, self).__init__()\n",
    "\n",
    "        self.model = timm.create_model(\"vit_base_patch16_224\", pretrained=False)\n",
    "        if pretrained:\n",
    "            self.model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "    def train_one_epoch(self, train_loader, criterion, optimizer, device):\n",
    "        # keep track of training loss\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "\n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        self.model.train()\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            elif device.type == \"xla\":\n",
    "                data = data.to(device, dtype=torch.float32)\n",
    "#                 print(target)\n",
    "                target = torch.tensor(target).to(device, dtype=torch.int64)\n",
    "\n",
    "            # clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = self.forward(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Calculate Accuracy\n",
    "            accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "            # update training loss and accuracy\n",
    "            epoch_loss += loss\n",
    "            epoch_accuracy += accuracy\n",
    "\n",
    "            # perform a single optimization step (parameter update)\n",
    "            if device.type == \"xla\":\n",
    "                xm.optimizer_step(optimizer)\n",
    "\n",
    "                if i % 20 == 0:\n",
    "                    xm.master_print(f\"\\tBATCH {i+1}/{len(train_loader)} - LOSS: {loss}\")\n",
    "\n",
    "            else:\n",
    "                optimizer.step()\n",
    "\n",
    "        return epoch_loss / len(train_loader), epoch_accuracy / len(train_loader)\n",
    "\n",
    "    def validate_one_epoch(self, valid_loader, criterion, device):\n",
    "        # keep track of validation loss\n",
    "        valid_loss = 0.0\n",
    "        valid_accuracy = 0.0\n",
    "\n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        self.model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            # move tensors to GPU if CUDA is available\n",
    "            if device.type == \"cuda\":\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            elif device.type == \"xla\":\n",
    "                data = data.to(device, dtype=torch.float32)\n",
    "                target = torch.tensor(target).to(device, dtype=torch.int64)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # forward pass: compute predicted outputs by passing inputs to the model\n",
    "                output = self.model(data)\n",
    "                # calculate the batch loss\n",
    "                loss = criterion(output, target)\n",
    "                # Calculate Accuracy\n",
    "                accuracy = (output.argmax(dim=1) == target).float().mean()\n",
    "                # update average validation loss and accuracy\n",
    "                valid_loss += loss\n",
    "                valid_accuracy += accuracy\n",
    "\n",
    "        return valid_loss / len(valid_loader), valid_accuracy / len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:01.992785Z",
     "iopub.status.busy": "2022-10-24T15:35:01.992476Z",
     "iopub.status.idle": "2022-10-24T15:35:06.757793Z",
     "shell.execute_reply": "2022-10-24T15:35:06.756959Z",
     "shell.execute_reply.started": "2022-10-24T15:35:01.992752Z"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "model = ViTBase16(n_classes=3, pretrained=True)\n",
    "\n",
    "def fit_tpu(\n",
    "    model, epochs, device, criterion, optimizer, train_loader, valid_loader=None\n",
    "):\n",
    "\n",
    "    valid_loss_min = np.Inf  # track change in validation loss\n",
    "\n",
    "    # keeping track of losses as it happen\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        gc.collect()\n",
    "        para_train_loader = pl.ParallelLoader(train_loader, [device])\n",
    "        \n",
    "        xm.master_print(f\"{'='*50}\")\n",
    "        xm.master_print(f\"EPOCH {epoch} - TRAINING...\")\n",
    "        train_loss, train_acc = model.train_one_epoch(\n",
    "            para_train_loader.per_device_loader(device), criterion, optimizer, device\n",
    "        )\n",
    "        xm.master_print(\n",
    "            f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}, ACCURACY: {train_acc}\\n\"\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        gc.collect()\n",
    "        \n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            para_valid_loader = pl.ParallelLoader(valid_loader, [device])\n",
    "            xm.master_print(f\"EPOCH {epoch} - VALIDATING...\")\n",
    "            valid_loss, valid_acc = model.validate_one_epoch(\n",
    "                para_valid_loader.per_device_loader(device), criterion, device\n",
    "            )\n",
    "            xm.master_print(f\"\\t[VALID] LOSS: {valid_loss}, ACCURACY: {valid_acc}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_accs.append(valid_acc)\n",
    "            gc.collect()\n",
    "\n",
    "            # save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min and epoch != 1:\n",
    "                xm.master_print(\n",
    "                    \"Validation loss decreased ({:.4f} --> {:.4f}).  Saving model ...\".format(\n",
    "                        valid_loss_min, valid_loss\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            valid_loss_min = valid_loss\n",
    "    logs={\n",
    "        \"train_loss\": train_losses,\n",
    "        \"valid_losses\": valid_losses,\n",
    "        \"train_acc\": train_accs,\n",
    "        \"valid_acc\": valid_accs,\n",
    "    }\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:06.759329Z",
     "iopub.status.busy": "2022-10-24T15:35:06.758865Z",
     "iopub.status.idle": "2022-10-24T15:35:06.770943Z",
     "shell.execute_reply": "2022-10-24T15:35:06.769986Z",
     "shell.execute_reply.started": "2022-10-24T15:35:06.759271Z"
    }
   },
   "outputs": [],
   "source": [
    "def _run():\n",
    "    train_dataset = SDSSDataset(train, transforms=transforms_train)\n",
    "    valid_dataset = SDSSDataset(val, transforms=transforms_valid,mode=\"valid\",)\n",
    "\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        train_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        valid_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=valid_sampler,\n",
    "        drop_last=True,\n",
    "        num_workers=8,\n",
    "    )\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    device = xm.xla_device()\n",
    "    model.to(device)\n",
    "    \n",
    "    lr = LR * xm.xrt_world_size()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    xm.master_print(f\"INITIALIZING TRAINING ON {xm.xrt_world_size()} TPU CORES\")\n",
    "    start_time = datetime.now()\n",
    "    xm.master_print(f\"Start Time: {start_time}\")\n",
    "\n",
    "    logs = fit_tpu(\n",
    "        model=model,\n",
    "        epochs=N_EPOCHS,\n",
    "        device=device,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "    )\n",
    "\n",
    "    xm.master_print(f\"Execution time: {datetime.now() - start_time}\")\n",
    "\n",
    "    xm.master_print(\"Saving Model\")\n",
    "    xm.save(\n",
    "        model.state_dict(), f'model_5e_{datetime.now().strftime(\"%Y%m%d-%H%M\")}.pth'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:35:06.773374Z",
     "iopub.status.busy": "2022-10-24T15:35:06.772776Z",
     "iopub.status.idle": "2022-10-24T15:42:23.889513Z",
     "shell.execute_reply": "2022-10-24T15:42:23.888101Z",
     "shell.execute_reply.started": "2022-10-24T15:35:06.773309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 15:35:06.842640: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.849946: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.870753: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.886190: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.903731: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.919535: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:06.937509: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n",
      "2022-10-24 15:35:16.272814: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:16.493286: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:16.502434: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:16.684300: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:16.694330: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:16.795109: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:16.802147: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING TRAINING ON 8 TPU CORES\n",
      "Start Time: 2022-10-24 15:35:17.511961\n",
      "==================================================\n",
      "EPOCH 1 - TRAINING...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 15:35:21.325088: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:21.337835: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:21.706392: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:21.725354: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:22.522835: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:22.536342: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:22.765674: I tensorflow/compiler/xla/xla_client/computation_client.cc:195] Fetching mesh configuration for worker tpu_worker:0 from mesh service at 304b85e62c1a:54739\n",
      "2022-10-24 15:35:22.776952: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n",
      "2022-10-24 15:35:06.919535: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tBATCH 1/31 - LOSS: 1.2734375\n",
      "\tBATCH 21/31 - LOSS: 0.212890625\n",
      "\n",
      "\t[TRAIN] EPOCH 1 - LOSS: 0.44140625, ACCURACY: 0.80859375\n",
      "\n",
      "EPOCH 1 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.1689453125, ACCURACY: 0.95703125\n",
      "\n",
      "==================================================\n",
      "EPOCH 2 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.150390625\n",
      "\tBATCH 21/31 - LOSS: 0.375\n",
      "\n",
      "\t[TRAIN] EPOCH 2 - LOSS: 0.251953125, ACCURACY: 0.9140625\n",
      "\n",
      "EPOCH 2 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.11962890625, ACCURACY: 0.96875\n",
      "\n",
      "Validation loss decreased (0.1689 --> 0.1196).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 3 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.208984375\n",
      "\tBATCH 21/31 - LOSS: 0.296875\n",
      "\n",
      "\t[TRAIN] EPOCH 3 - LOSS: 0.2236328125, ACCURACY: 0.91015625\n",
      "\n",
      "EPOCH 3 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.08984375, ACCURACY: 0.96875\n",
      "\n",
      "Validation loss decreased (0.1196 --> 0.0898).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 4 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.08447265625\n",
      "\tBATCH 21/31 - LOSS: 0.2119140625\n",
      "\n",
      "\t[TRAIN] EPOCH 4 - LOSS: 0.2109375, ACCURACY: 0.9296875\n",
      "\n",
      "EPOCH 4 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.10302734375, ACCURACY: 0.95703125\n",
      "\n",
      "==================================================\n",
      "EPOCH 5 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.1220703125\n",
      "\tBATCH 21/31 - LOSS: 0.29296875\n",
      "\n",
      "\t[TRAIN] EPOCH 5 - LOSS: 0.18359375, ACCURACY: 0.9296875\n",
      "\n",
      "EPOCH 5 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.08984375, ACCURACY: 0.96875\n",
      "\n",
      "Validation loss decreased (0.1030 --> 0.0898).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 6 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.07568359375\n",
      "\tBATCH 21/31 - LOSS: 0.2275390625\n",
      "\n",
      "\t[TRAIN] EPOCH 6 - LOSS: 0.1923828125, ACCURACY: 0.93359375\n",
      "\n",
      "EPOCH 6 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.12109375, ACCURACY: 0.9375\n",
      "\n",
      "==================================================\n",
      "EPOCH 7 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.2080078125\n",
      "\tBATCH 21/31 - LOSS: 0.1962890625\n",
      "\n",
      "\t[TRAIN] EPOCH 7 - LOSS: 0.17578125, ACCURACY: 0.9296875\n",
      "\n",
      "EPOCH 7 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.08056640625, ACCURACY: 0.95703125\n",
      "\n",
      "Validation loss decreased (0.1211 --> 0.0806).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 8 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.1611328125\n",
      "\tBATCH 21/31 - LOSS: 0.294921875\n",
      "\n",
      "\t[TRAIN] EPOCH 8 - LOSS: 0.1640625, ACCURACY: 0.93359375\n",
      "\n",
      "EPOCH 8 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.0751953125, ACCURACY: 0.98046875\n",
      "\n",
      "Validation loss decreased (0.0806 --> 0.0752).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 9 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.08740234375\n",
      "\tBATCH 21/31 - LOSS: 0.2138671875\n",
      "\n",
      "\t[TRAIN] EPOCH 9 - LOSS: 0.1806640625, ACCURACY: 0.9453125\n",
      "\n",
      "EPOCH 9 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.07177734375, ACCURACY: 0.98046875\n",
      "\n",
      "Validation loss decreased (0.0752 --> 0.0718).  Saving model ...\n",
      "==================================================\n",
      "EPOCH 10 - TRAINING...\n",
      "\tBATCH 1/31 - LOSS: 0.0927734375\n",
      "\tBATCH 21/31 - LOSS: 0.162109375\n",
      "\n",
      "\t[TRAIN] EPOCH 10 - LOSS: 0.189453125, ACCURACY: 0.93359375\n",
      "\n",
      "EPOCH 10 - VALIDATING...\n",
      "\t[VALID] LOSS: 0.09619140625, ACCURACY: 0.95703125\n",
      "\n",
      "Execution time: 0:07:03.771442\n",
      "Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 15:42:22.672683: I tensorflow/compiler/xla/xla_client/mesh_service.cc:234] Waiting to connect to client mesh master (300 seconds) 304b85e62c1a:54739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 273 ms, sys: 193 ms, total: 466 ms\n",
      "Wall time: 7min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Start training processes\n",
    "def _mp_fn(rank, flags):\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "    a = _run()\n",
    "\n",
    "\n",
    "# _run()\n",
    "FLAGS = {}\n",
    "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method=\"fork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:42:23.892580Z",
     "iopub.status.busy": "2022-10-24T15:42:23.892191Z",
     "iopub.status.idle": "2022-10-24T15:42:25.032506Z",
     "shell.execute_reply": "2022-10-24T15:42:25.031430Z",
     "shell.execute_reply.started": "2022-10-24T15:42:23.892509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb\n",
      "images\n",
      "model_5e_20221024-1542.pth\n",
      "pytorch-xla-env-setup.py\n",
      "torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:42:25.035085Z",
     "iopub.status.busy": "2022-10-24T15:42:25.034690Z",
     "iopub.status.idle": "2022-10-24T15:42:26.414229Z",
     "shell.execute_reply": "2022-10-24T15:42:26.412659Z",
     "shell.execute_reply.started": "2022-10-24T15:42:25.035038Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -r images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:42:26.416970Z",
     "iopub.status.busy": "2022-10-24T15:42:26.416659Z",
     "iopub.status.idle": "2022-10-24T15:42:27.538754Z",
     "shell.execute_reply": "2022-10-24T15:42:27.537714Z",
     "shell.execute_reply.started": "2022-10-24T15:42:26.416936Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook_source__.ipynb\n",
      "model_5e_20221024-1542.pth\n",
      "pytorch-xla-env-setup.py\n",
      "torch-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "torch_xla-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n",
      "torchvision-nightly+20200515-cp37-cp37m-linux_x86_64.whl\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:42:27.542025Z",
     "iopub.status.busy": "2022-10-24T15:42:27.541027Z",
     "iopub.status.idle": "2022-10-24T15:42:32.375967Z",
     "shell.execute_reply": "2022-10-24T15:42:32.375106Z",
     "shell.execute_reply.started": "2022-10-24T15:42:27.541975Z"
    }
   },
   "outputs": [],
   "source": [
    "model_inference = ViTBase16(n_classes=3, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T15:57:36.906054Z",
     "iopub.status.busy": "2022-10-24T15:57:36.905279Z",
     "iopub.status.idle": "2022-10-24T15:57:37.814227Z",
     "shell.execute_reply": "2022-10-24T15:57:37.813166Z",
     "shell.execute_reply.started": "2022-10-24T15:57:36.906013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inference.load_state_dict(torch.load(\"./model_5e_20221024-1542.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:11:27.109385Z",
     "iopub.status.busy": "2022-10-24T16:11:27.108450Z",
     "iopub.status.idle": "2022-10-24T16:11:27.121833Z",
     "shell.execute_reply": "2022-10-24T16:11:27.120076Z",
     "shell.execute_reply.started": "2022-10-24T16:11:27.109314Z"
    }
   },
   "outputs": [],
   "source": [
    "class SDSSDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Helper Class to create the pytorch dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df, data_path=DATA_PATH, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df_data = df.values\n",
    "        self.data_path = data_path\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.data_dir = \"./images/test\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label,img_name = self.df_data[index]\n",
    "        img_path = os.path.join(self.data_dir, img_name)\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(img)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:11:27.363239Z",
     "iopub.status.busy": "2022-10-24T16:11:27.362930Z",
     "iopub.status.idle": "2022-10-24T16:11:27.372415Z",
     "shell.execute_reply": "2022-10-24T16:11:27.371332Z",
     "shell.execute_reply.started": "2022-10-24T16:11:27.363209Z"
    }
   },
   "outputs": [],
   "source": [
    "transforms_valid = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_dataset = SDSSDataset(test, transforms=transforms_valid)\n",
    "test_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "        test_dataset,\n",
    "        num_replicas=xm.xrt_world_size(),\n",
    "        rank=xm.get_ordinal(),\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "dataset=test_dataset,\n",
    "batch_size=1,\n",
    "sampler=test_sampler,\n",
    "drop_last=True,\n",
    "num_workers=8,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:11:55.959228Z",
     "iopub.status.busy": "2022-10-24T16:11:55.958923Z",
     "iopub.status.idle": "2022-10-24T16:11:59.462142Z",
     "shell.execute_reply": "2022-10-24T16:11:59.460713Z",
     "shell.execute_reply.started": "2022-10-24T16:11:55.959200Z"
    }
   },
   "outputs": [],
   "source": [
    "!rm -r images\n",
    "!mkdir images\n",
    "!mkdir images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:11:59.466622Z",
     "iopub.status.busy": "2022-10-24T16:11:59.466174Z",
     "iopub.status.idle": "2022-10-24T16:12:05.488010Z",
     "shell.execute_reply": "2022-10-24T16:12:05.486895Z",
     "shell.execute_reply.started": "2022-10-24T16:11:59.466569Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for img in test['image']:\n",
    "    shutil.copy(\"../input/sdss-images/images (1)/images/\"+img,\"./images/test/\"+img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:12:11.653043Z",
     "iopub.status.busy": "2022-10-24T16:12:11.652701Z",
     "iopub.status.idle": "2022-10-24T16:12:12.125182Z",
     "shell.execute_reply": "2022-10-24T16:12:12.122642Z",
     "shell.execute_reply.started": "2022-10-24T16:12:11.653008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for x in test_loader:\n",
    "    print(len(x))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:12:14.633831Z",
     "iopub.status.busy": "2022-10-24T16:12:14.633439Z",
     "iopub.status.idle": "2022-10-24T16:12:14.644600Z",
     "shell.execute_reply": "2022-10-24T16:12:14.643161Z",
     "shell.execute_reply.started": "2022-10-24T16:12:14.633794Z"
    }
   },
   "outputs": [],
   "source": [
    "model_inf = model_inference.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:12:15.540939Z",
     "iopub.status.busy": "2022-10-24T16:12:15.540420Z",
     "iopub.status.idle": "2022-10-24T16:12:16.701271Z",
     "shell.execute_reply": "2022-10-24T16:12:16.700528Z",
     "shell.execute_reply.started": "2022-10-24T16:12:15.540883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.2374, -2.8192, -3.7498]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inf(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:12:18.657661Z",
     "iopub.status.busy": "2022-10-24T16:12:18.656978Z",
     "iopub.status.idle": "2022-10-24T16:12:25.426519Z",
     "shell.execute_reply": "2022-10-24T16:12:25.425397Z",
     "shell.execute_reply.started": "2022-10-24T16:12:18.657592Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-24 16:12:24.537690: I torch_xla/csrc/tensor_util.cpp:28] Using BF16 data type for floating point values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moved\n"
     ]
    }
   ],
   "source": [
    "device = xm.xla_device()\n",
    "\n",
    "model_inf.to(device)\n",
    "print(\"moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:12:31.494874Z",
     "iopub.status.busy": "2022-10-24T16:12:31.494511Z",
     "iopub.status.idle": "2022-10-24T16:12:56.041843Z",
     "shell.execute_reply": "2022-10-24T16:12:56.040151Z",
     "shell.execute_reply.started": "2022-10-24T16:12:31.494839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "340f933b18a949bebfbc283e317f100a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Exception ignored in: \n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "Traceback (most recent call last):\n",
      "    \n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>    self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: \n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "\n",
      "    Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "    self._shutdown_workers()w.join()Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "self._shutdown_workers()\n",
      "    \n",
      "self._shutdown_workers()      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "\n",
      "          File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "self._shutdown_workers()w.join()\n",
      "\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "      File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "self._shutdown_workers()w.join()        self._shutdown_workers()    w.join()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "w.join()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "w.join()      File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "        AssertionErrorw.join()\n",
      "\n",
      "    AssertionErrorassert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      ": w.join()  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process': \n",
      "can only join a child process  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "    \n",
      "    can only join a child process    AssertionErrorassert self._parent_pid == os.getpid(), 'can only join a child process'AssertionError  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      ": assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process': can only join a child processAssertionError    can only join a child process\n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only join a child process'AssertionError: \n",
      "can only join a child process: \n",
      ": can only join a child process\n",
      "\n",
      "\n",
      "AssertionErrorcan only join a child process: Exception ignored in: \n",
      "Exception ignored in: can only join a child processException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050><function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Exception ignored in:     \n",
      "\n",
      "    Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>    self._shutdown_workers()Traceback (most recent call last):\n",
      "Exception ignored in: self._shutdown_workers()  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "\n",
      "self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "    \n",
      "Traceback (most recent call last):\n",
      "\n",
      "self._shutdown_workers()  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Exception ignored in:   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "    <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "        \n",
      "self._shutdown_workers()w.join()    self._shutdown_workers()  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "w.join()  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "        Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "w.join()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "    w.join()    \n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "    \n",
      "self._shutdown_workers()w.join()AssertionError  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "    \n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "w.join(): \n",
      "can only join a child process\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "      File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'            self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "w.join()assert self._parent_pid == os.getpid(), 'can only join a child process'  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "\n",
      "    \n",
      "AssertionErrorAssertionError  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      ": \n",
      ":     assert self._parent_pid == os.getpid(), 'can only join a child process'can only join a child process    can only join a child process\n",
      "AssertionError\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "Exception ignored in: \n",
      "AssertionError<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "w.join(): AssertionError\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      ": can only join a child processAssertionError\n",
      ":     can only join a child process: assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError:   File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "can only join a child processcan only join a child process\n",
      "\n",
      "    self._shutdown_workers()\n",
      "\n",
      "can only join a child process\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "Exception ignored in: Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>    \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Traceback (most recent call last):\n",
      "Exception ignored in: w.join()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "        Traceback (most recent call last):\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'Exception ignored in: Exception ignored in: Traceback (most recent call last):\n",
      "self._shutdown_workers()\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "AssertionErrorException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "\n",
      "    : <function _MultiProcessingDataLoaderIter.__del__ at 0x7fe85673a050>    \n",
      "\n",
      "Traceback (most recent call last):\n",
      "can only join a child processself._shutdown_workers()Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "self._shutdown_workers()      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1079, in __del__\n",
      "self._shutdown_workers()    \n",
      "w.join()  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "w.join()        \n",
      "              File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "w.join()self._shutdown_workers()w.join()\n",
      "w.join()    \n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "self._shutdown_workers()\n",
      "AssertionError        :       File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process'    can only join a child processassert self._parent_pid == os.getpid(), 'can only join a child process'w.join()\n",
      "\n",
      "\n",
      "AssertionError\n",
      "    AssertionError  File \"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 1059, in _shutdown_workers\n",
      ":   File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      "assert self._parent_pid == os.getpid(), 'can only join a child process': can only join a child processcan only join a child process    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "    AssertionErrorw.join(): assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "\n",
      "\n",
      "\n",
      "can only join a child processAssertionError  File \"/opt/conda/lib/python3.7/multiprocessing/process.py\", line 138, in join\n",
      ": AssertionErrorcan only join a child process\n",
      ": can only join a child process\n",
      "\n",
      "    assert self._parent_pid == os.getpid(), 'can only join a child process'\n",
      "AssertionError: can only join a child process\n"
     ]
    }
   ],
   "source": [
    "test_preds = list()\n",
    "\n",
    "# device = xm.xla_device()\n",
    "# model.to(device)\n",
    "\n",
    "for x in tqdm(test_loader):\n",
    "    test_preds.append(model_inf(x[0].to(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:05.486752Z",
     "iopub.status.busy": "2022-10-24T16:13:05.486112Z",
     "iopub.status.idle": "2022-10-24T16:13:20.940467Z",
     "shell.execute_reply": "2022-10-24T16:13:20.939385Z",
     "shell.execute_reply.started": "2022-10-24T16:13:05.486698Z"
    }
   },
   "outputs": [],
   "source": [
    "test_preds = [list(x.cpu().detach().numpy()[0]) for x in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:21.030229Z",
     "iopub.status.busy": "2022-10-24T16:13:21.028902Z",
     "iopub.status.idle": "2022-10-24T16:13:21.046147Z",
     "shell.execute_reply": "2022-10-24T16:13:21.045131Z",
     "shell.execute_reply.started": "2022-10-24T16:13:21.030169Z"
    }
   },
   "outputs": [],
   "source": [
    "test_labels = [np.argmax(x) for x in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:21.048373Z",
     "iopub.status.busy": "2022-10-24T16:13:21.047836Z",
     "iopub.status.idle": "2022-10-24T16:13:21.054753Z",
     "shell.execute_reply": "2022-10-24T16:13:21.053498Z",
     "shell.execute_reply.started": "2022-10-24T16:13:21.048333Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:21.444015Z",
     "iopub.status.busy": "2022-10-24T16:13:21.443686Z",
     "iopub.status.idle": "2022-10-24T16:13:25.122162Z",
     "shell.execute_reply": "2022-10-24T16:13:25.120901Z",
     "shell.execute_reply.started": "2022-10-24T16:13:21.443983Z"
    }
   },
   "outputs": [],
   "source": [
    "true_labels = list()\n",
    "for x in test_loader:\n",
    "    true_labels.append(x[1].detach().cpu().numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:27.454644Z",
     "iopub.status.busy": "2022-10-24T16:13:27.453401Z",
     "iopub.status.idle": "2022-10-24T16:13:27.459405Z",
     "shell.execute_reply": "2022-10-24T16:13:27.458402Z",
     "shell.execute_reply.started": "2022-10-24T16:13:27.454592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:32.166705Z",
     "iopub.status.busy": "2022-10-24T16:13:32.165377Z",
     "iopub.status.idle": "2022-10-24T16:13:32.174543Z",
     "shell.execute_reply": "2022-10-24T16:13:32.173453Z",
     "shell.execute_reply.started": "2022-10-24T16:13:32.166651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 2, 2, 2, 1, 2, 2, 0, 0, 2], [0, 2, 2, 2, 1, 2, 2, 0, 0, 2])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:10],true_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-24T16:13:38.482176Z",
     "iopub.status.busy": "2022-10-24T16:13:38.481803Z",
     "iopub.status.idle": "2022-10-24T16:13:38.501145Z",
     "shell.execute_reply": "2022-10-24T16:13:38.500087Z",
     "shell.execute_reply.started": "2022-10-24T16:13:38.482137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['              precision    recall  f1-score   support',\n",
       " '',\n",
       " '           0       0.97      0.99      0.98       481',\n",
       " '           1       0.82      0.70      0.76       100',\n",
       " '           2       0.95      0.95      0.95       419',\n",
       " '',\n",
       " '    accuracy                           0.95      1000',\n",
       " '   macro avg       0.91      0.88      0.90      1000',\n",
       " 'weighted avg       0.94      0.95      0.94      1000',\n",
       " '']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(test_labels,true_labels).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
