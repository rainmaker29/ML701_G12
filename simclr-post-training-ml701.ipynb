{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Standard libraries\nimport os\nfrom copy import deepcopy\n\n## Imports for plotting\nimport matplotlib.pyplot as plt\nplt.set_cmap('cividis')\n%matplotlib inline\nfrom IPython.display import set_matplotlib_formats\nset_matplotlib_formats('svg', 'pdf') # For export\nimport matplotlib\nmatplotlib.rcParams['lines.linewidth'] = 2.0\nimport seaborn as sns\nsns.set()\n\n## tqdm for loading bars\nfrom tqdm.notebook import tqdm\n\n## PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as data\nimport torch.optim as optim\n\n## Torchvision\nimport torchvision\nfrom torchvision.datasets import STL10\nfrom torchvision import transforms\n\n# PyTorch Lightning\ntry:\n    import pytorch_lightning as pl\nexcept ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n    !pip install --quiet pytorch-lightning>=1.4\n    import pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n# Import tensorboard\n%load_ext tensorboard\n\nNUM_WORKERS = os.cpu_count()\n\n# Setting the seed\npl.seed_everything(42)\n\n# Ensure that all operations are deterministic on GPU (if used) for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(\"Device:\", device)\nprint(\"Number of workers:\", NUM_WORKERS)","metadata":{"id":"dDqfYwVJxJxS","outputId":"bbdb5c9f-5fd4-4208-efdf-a1806ce106ff","papermill":{"duration":5.224027,"end_time":"2022-11-19T11:03:20.527346","exception":false,"start_time":"2022-11-19T11:03:15.303319","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T16:14:22.907080Z","iopub.execute_input":"2022-12-01T16:14:22.907776Z","iopub.status.idle":"2022-12-01T16:14:22.935030Z","shell.execute_reply.started":"2022-12-01T16:14:22.907741Z","shell.execute_reply":"2022-12-01T16:14:22.933789Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\nDevice: cuda:0\nNumber of workers: 2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n  # Remove the CWD from sys.path while we load stuff.\n","output_type":"stream"}]},{"cell_type":"code","source":"import urllib.request\nfrom urllib.error import HTTPError\nfrom torchvision import transforms\nimport os\n\n# # Files to download\n# pretrained_files = [\"SimCLR.ckpt\", \"ResNet.ckpt\",\n#                     \"tensorboards/SimCLR/events.out.tfevents.SimCLR\",\n#                     \"tensorboards/classification/ResNet/events.out.tfevents.ResNet\"]\n# pretrained_files += [f\"LogisticRegression_{size}.ckpt\" for size in [10, 20, 50, 100, 200, 500]]","metadata":{"id":"zyX8NZlTxJxU","papermill":{"duration":0.018782,"end_time":"2022-11-19T11:03:20.555334","exception":false,"start_time":"2022-11-19T11:03:20.536552","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:32.740561Z","iopub.execute_input":"2022-12-01T15:53:32.741308Z","iopub.status.idle":"2022-12-01T15:53:32.749570Z","shell.execute_reply.started":"2022-12-01T15:53:32.741270Z","shell.execute_reply":"2022-12-01T15:53:32.747164Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class ContrastiveTransformations(object):\n    \n    def __init__(self, base_transforms, n_views=2):\n        self.base_transforms = base_transforms\n        self.n_views = n_views\n        \n    def __call__(self, x):\n        return [self.base_transforms(x) for i in range(self.n_views)]","metadata":{"id":"65KfmJQCxJxW","papermill":{"duration":0.017106,"end_time":"2022-11-19T11:03:20.581131","exception":false,"start_time":"2022-11-19T11:03:20.564025","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:32.751937Z","iopub.execute_input":"2022-12-01T15:53:32.753209Z","iopub.status.idle":"2022-12-01T15:53:32.763311Z","shell.execute_reply.started":"2022-12-01T15:53:32.753171Z","shell.execute_reply":"2022-12-01T15:53:32.762402Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"contrast_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n                                          transforms.RandomResizedCrop(size=96),\n                                          transforms.RandomApply([\n                                              transforms.ColorJitter(brightness=0.5, \n                                                                     contrast=0.5, \n                                                                     saturation=0.5, \n                                                                     hue=0.1)\n                                          ], p=0.8),\n                                          transforms.RandomGrayscale(p=0.2),\n                                          transforms.GaussianBlur(kernel_size=9),\n                                          transforms.ToTensor(),\n                                          transforms.Normalize((0.5,), (0.5,))\n                                         ])","metadata":{"id":"61tnj1NAxJxX","papermill":{"duration":0.017458,"end_time":"2022-11-19T11:03:20.608459","exception":false,"start_time":"2022-11-19T11:03:20.591001","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:32.766469Z","iopub.execute_input":"2022-12-01T15:53:32.766944Z","iopub.status.idle":"2022-12-01T15:53:32.773701Z","shell.execute_reply.started":"2022-12-01T15:53:32.766849Z","shell.execute_reply":"2022-12-01T15:53:32.772639Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/sdss-images/data.csv\")\ndf.iloc[0][\"image\"]","metadata":{"papermill":{"duration":0.05522,"end_time":"2022-11-19T11:03:20.672447","exception":false,"start_time":"2022-11-19T11:03:20.617227","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:32.775305Z","iopub.execute_input":"2022-12-01T15:53:32.775834Z","iopub.status.idle":"2022-12-01T15:53:32.816155Z","shell.execute_reply.started":"2022-12-01T15:53:32.775799Z","shell.execute_reply":"2022-12-01T15:53:32.815400Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'image_0000.jpg'"},"metadata":{}}]},{"cell_type":"code","source":"df['class'].value_counts()","metadata":{"papermill":{"duration":0.023024,"end_time":"2022-11-19T11:03:20.721704","exception":false,"start_time":"2022-11-19T11:03:20.698680","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:32.817916Z","iopub.execute_input":"2022-12-01T15:53:32.818556Z","iopub.status.idle":"2022-12-01T15:53:32.830275Z","shell.execute_reply.started":"2022-12-01T15:53:32.818520Z","shell.execute_reply":"2022-12-01T15:53:32.829177Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"GALAXY    4998\nSTAR      4152\nQSO        850\nName: class, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nimport torch.nn.functional as nnf\nfrom torch.utils.data.dataset import Dataset\nfrom skimage import io as skio\nfrom skimage import transform\nfrom torchvision import transforms as T\n\nclass SDSSDataset(Dataset):\n    def __init__(self, csv_file, root_dir):\n        self.df = pd.read_csv(csv_file)\n        label_dict = {'GALAXY':0,'STAR':1,'QSO':2}\n        self.df['class'] = self.df['class'].apply(lambda x : label_dict[x])\n        print(self.df.head(2))\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,self.df.iloc[idx][\"image\"])\n        image = skio.imread(img_name).reshape(3,128,128).astype(np.float32)\n        torch_tensor = torch.from_numpy(image).unsqueeze(0)\n        out = nnf.interpolate(torch_tensor, size=(96, 96), mode='nearest').squeeze(0)\n        image = out.cpu().detach().numpy().reshape(3,96,96)\n        label = self.df.iloc[idx][\"class\"]\n        return image,label","metadata":{"papermill":{"duration":0.48787,"end_time":"2022-11-19T11:03:21.218629","exception":false,"start_time":"2022-11-19T11:03:20.730759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T16:15:21.656624Z","iopub.execute_input":"2022-12-01T16:15:21.656988Z","iopub.status.idle":"2022-12-01T16:15:21.668326Z","shell.execute_reply.started":"2022-12-01T16:15:21.656957Z","shell.execute_reply":"2022-12-01T16:15:21.667359Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport pandas as pd\nbalanced_set = pd.read_csv(\"../input/sdss-images/equal_splits.csv\")\nprint(balanced_set.columns)\nbalanced_images = list(balanced_set[balanced_set.columns[1]])\nbalanced_images.extend(list(balanced_set[balanced_set.columns[2]]))\nbalanced_images.extend(list(balanced_set[balanced_set.columns[3]]))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:33.279938Z","iopub.execute_input":"2022-12-01T15:53:33.280510Z","iopub.status.idle":"2022-12-01T15:53:33.295159Z","shell.execute_reply.started":"2022-12-01T15:53:33.280477Z","shell.execute_reply":"2022-12-01T15:53:33.294296Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Index(['Unnamed: 0', 'trimmed traininng  qalaxy', 'trimmed traininng  qsd',\n       'trimmed traininng  star'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"!rm -rf balanced_images/*\n!mkdir balanced_images","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:33.299776Z","iopub.execute_input":"2022-12-01T15:53:33.300057Z","iopub.status.idle":"2022-12-01T15:53:35.247647Z","shell.execute_reply.started":"2022-12-01T15:53:33.300024Z","shell.execute_reply":"2022-12-01T15:53:35.246339Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for img in balanced_images:\n    shutil.copy(\"../input/sdss-images/images (1)/images/\"+img,\"./balanced_images/\"+img)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:35.250590Z","iopub.execute_input":"2022-12-01T15:53:35.251414Z","iopub.status.idle":"2022-12-01T15:53:41.908069Z","shell.execute_reply.started":"2022-12-01T15:53:35.251368Z","shell.execute_reply":"2022-12-01T15:53:41.907072Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/sdss-images/data.csv\")\nbalanced_df = df.loc[df['image'].isin(balanced_images)].reset_index().drop(['index'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:41.911478Z","iopub.execute_input":"2022-12-01T15:53:41.911784Z","iopub.status.idle":"2022-12-01T15:53:41.935631Z","shell.execute_reply.started":"2022-12-01T15:53:41.911757Z","shell.execute_reply":"2022-12-01T15:53:41.934770Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nbalanced_train,balanced_test = train_test_split(balanced_df,test_size=0.2,stratify=balanced_df['class'])\nbalanced_train.to_csv(\"balanced_train.csv\",index=False),balanced_test.to_csv(\"balanced_test.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:41.937088Z","iopub.execute_input":"2022-12-01T15:53:41.937462Z","iopub.status.idle":"2022-12-01T15:53:42.048154Z","shell.execute_reply.started":"2022-12-01T15:53:41.937427Z","shell.execute_reply":"2022-12-01T15:53:42.047082Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(None, None)"},"metadata":{}}]},{"cell_type":"code","source":"class SimCLR(pl.LightningModule):\n    \n    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500):\n        super().__init__()\n        self.save_hyperparameters()\n        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n        # Base model f(.)\n        self.convnet = torchvision.models.resnet18(num_classes=4*hidden_dim)  # Output of last linear layer\n        # The MLP for g(.) consists of Linear->ReLU->Linear \n        self.convnet.fc = nn.Sequential(\n            self.convnet.fc,  # Linear(ResNet output, 4*hidden_dim)\n            nn.ReLU(inplace=True),\n            nn.Linear(4*hidden_dim, hidden_dim)\n        )\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), \n                                lr=self.hparams.lr, \n                                weight_decay=self.hparams.weight_decay)\n        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n                                                            T_max=self.hparams.max_epochs,\n                                                            eta_min=self.hparams.lr/50)\n        return [optimizer], [lr_scheduler]\n        \n    def info_nce_loss(self, batch, mode='train'):\n        imgs, _ = batch\n        imgs = list([i.cpu().detach().numpy() for i in imgs])\n        imgs = torch.tensor(imgs).to(device)\n        # Encode all images\n        feats = self.convnet(imgs.float())\n        # Calculate cosine similarity\n        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n        # Mask out cosine similarity to itself\n        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n        cos_sim.masked_fill_(self_mask, -9e15)\n        # Find positive example -> batch_size//2 away from the original example\n        pos_mask = self_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n        # InfoNCE loss\n        cos_sim = cos_sim / self.hparams.temperature\n        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n        nll = nll.mean()\n        \n        # Logging loss\n        self.log(mode+'_loss', nll)\n        # Get ranking position of positive example\n        comb_sim = torch.cat([cos_sim[pos_mask][:,None],  # First position positive example\n                              cos_sim.masked_fill(pos_mask, -9e15)], \n                             dim=-1)\n        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n        # Logging ranking metrics\n        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean())\n        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean())\n        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean())\n        \n        return nll\n        \n    def training_step(self, batch, batch_idx):\n        \n        return self.info_nce_loss(batch, mode='train')\n        \n    def validation_step(self, batch, batch_idx):\n        self.info_nce_loss(batch, mode='val')\n        ","metadata":{"id":"Kou3wy9ExJxZ","papermill":{"duration":0.02609,"end_time":"2022-11-19T11:03:21.347928","exception":false,"start_time":"2022-11-19T11:03:21.321838","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:42.056933Z","iopub.execute_input":"2022-12-01T15:53:42.057871Z","iopub.status.idle":"2022-12-01T15:53:42.074019Z","shell.execute_reply.started":"2022-12-01T15:53:42.057835Z","shell.execute_reply":"2022-12-01T15:53:42.073031Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model = SimCLR(hidden_dim=128,lr=5e-4,temperature=0.07,weight_decay=1e-4,max_epochs=50)\nmodel.load_state_dict(torch.load(\"../input/simclr-ml701/simclr_resnet.pth\"))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:53:42.077470Z","iopub.execute_input":"2022-12-01T15:53:42.077856Z","iopub.status.idle":"2022-12-01T15:53:43.078154Z","shell.execute_reply.started":"2022-12-01T15:53:42.077830Z","shell.execute_reply":"2022-12-01T15:53:43.077156Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"def train_simclr(batch_size, max_epochs=500, **kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, 'SimCLR'),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=max_epochs,\n                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n                                    LearningRateMonitor('epoch')])\n    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'SimCLR.ckpt')\n    if os.path.isfile(pretrained_filename):\n        print(f'Found pretrained model at {pretrained_filename}, loading...')\n        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n    else:\n        train_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=True, \n                                       drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)\n        val_loader = data.DataLoader(dataset, batch_size=batch_size, shuffle=False, \n                                     drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n        pl.seed_everything(42) # To be reproducable\n        model = SimCLR(max_epochs=max_epochs, **kwargs)\n        trainer.fit(model, train_loader, val_loader)\n        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n\n    return model","metadata":{"id":"N-TlGO19xJxa","papermill":{"duration":0.02001,"end_time":"2022-11-19T11:03:21.412810","exception":false,"start_time":"2022-11-19T11:03:21.392800","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:43.079714Z","iopub.execute_input":"2022-12-01T15:53:43.080074Z","iopub.status.idle":"2022-12-01T15:53:43.089573Z","shell.execute_reply.started":"2022-12-01T15:53:43.080038Z","shell.execute_reply":"2022-12-01T15:53:43.088330Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class LogisticRegression(pl.LightningModule):\n    \n    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=100):\n        super().__init__()\n        self.save_hyperparameters()\n        # Mapping from representation h to classes\n        self.model = nn.Linear(feature_dim, num_classes)\n\n    def configure_optimizers(self):\n        optimizer = optim.AdamW(self.parameters(), \n                                lr=self.hparams.lr, \n                                weight_decay=self.hparams.weight_decay)\n        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n                                                      milestones=[int(self.hparams.max_epochs*0.6), \n                                                                  int(self.hparams.max_epochs*0.8)], \n                                                      gamma=0.1)\n        return [optimizer], [lr_scheduler]\n        \n    def _calculate_loss(self, batch, mode='train'):\n        feats, labels = batch\n        preds = self.model(feats)\n        loss = F.cross_entropy(preds, labels)\n        acc = (preds.argmax(dim=-1) == labels).float().mean()\n\n        self.log(mode + '_loss', loss)\n        self.log(mode + '_acc', acc)\n        return loss        \n        \n    def training_step(self, batch, batch_idx):\n        return self._calculate_loss(batch, mode='train')\n        \n    def validation_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode='val')\n        \n    def test_step(self, batch, batch_idx):\n        self._calculate_loss(batch, mode='test')\n    \n    def forward(self,batch):\n        return self.model(batch)","metadata":{"id":"d-FQ2pkCxJxc","papermill":{"duration":0.037267,"end_time":"2022-11-19T14:49:08.915318","exception":false,"start_time":"2022-11-19T14:49:08.878051","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:43.091308Z","iopub.execute_input":"2022-12-01T15:53:43.091673Z","iopub.status.idle":"2022-12-01T15:53:43.104343Z","shell.execute_reply.started":"2022-12-01T15:53:43.091637Z","shell.execute_reply":"2022-12-01T15:53:43.103363Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"img_transforms = transforms.Compose([transforms.ToTensor(),\n                                     transforms.Normalize((0.5,), (0.5,))])\ntrain_img_data = SDSSDataset(\"./balanced_train.csv\",\"./balanced_images\")\ntest_img_data = SDSSDataset(\"./balanced_test.csv\",\"./balanced_images\")\nprint(\"Number of training examples:\", len(train_img_data))\nprint(\"Number of test examples:\", len(test_img_data))","metadata":{"id":"w-Og_ARjxJxc","outputId":"24b7dc3f-810c-4529-de5e-d61784b0f87c","papermill":{"duration":0.022704,"end_time":"2022-11-19T14:49:08.989635","exception":false,"start_time":"2022-11-19T14:49:08.966931","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:43.105889Z","iopub.execute_input":"2022-12-01T15:53:43.106304Z","iopub.status.idle":"2022-12-01T15:53:43.130207Z","shell.execute_reply.started":"2022-12-01T15:53:43.106270Z","shell.execute_reply":"2022-12-01T15:53:43.129348Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"   class           image\n0      2  image_7444.jpg\n1      0  image_1163.jpg\n   class           image\n0      1  image_0846.jpg\n1      0  image_9084.jpg\nNumber of training examples: 1560\nNumber of test examples: 390\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<!-- Next, we implement a small function to encode all images in our datasets. The output representations are then used as inputs to the Logistic Regression model. -->","metadata":{"id":"NnTEewUhxJxc","papermill":{"duration":0.015992,"end_time":"2022-11-19T14:49:09.020784","exception":false,"start_time":"2022-11-19T14:49:09.004792","status":"completed"},"tags":[]}},{"cell_type":"code","source":"@torch.no_grad()\ndef prepare_data_features(model, dataset):\n    # Prepare model\n    network = deepcopy(model.convnet)\n    network.fc = nn.Identity()  # Removing projection head g(.)\n    network.eval()\n    network.to(device)\n    \n    # Encode all images\n    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=NUM_WORKERS, shuffle=False, drop_last=False)\n    feats, labels = [], []\n    for batch_imgs, batch_labels in tqdm(data_loader):\n        batch_imgs = batch_imgs.to(device)\n        batch_feats = network(batch_imgs)\n        feats.append(batch_feats.detach().cpu())\n        labels.append(batch_labels)\n    \n    feats = torch.cat(feats, dim=0)\n    labels = torch.cat(labels, dim=0)\n    \n    # Sort images by labels\n    labels, idxs = labels.sort()\n    feats = feats[idxs]\n    \n    return data.TensorDataset(feats, labels)","metadata":{"id":"7CK6vIrpxJxd","papermill":{"duration":0.02313,"end_time":"2022-11-19T14:49:09.059328","exception":false,"start_time":"2022-11-19T14:49:09.036198","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:43.133021Z","iopub.execute_input":"2022-12-01T15:53:43.133299Z","iopub.status.idle":"2022-12-01T15:53:43.143079Z","shell.execute_reply.started":"2022-12-01T15:53:43.133274Z","shell.execute_reply":"2022-12-01T15:53:43.142154Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_feats_simclr = prepare_data_features(model, train_img_data)\ntest_feats_simclr = prepare_data_features(model, test_img_data)","metadata":{"id":"C7gWrDH8xJxd","outputId":"c793aaf1-74bd-4647-ee87-9a2f6ed226fe","papermill":{"duration":0.035286,"end_time":"2022-11-19T14:49:09.140045","exception":false,"start_time":"2022-11-19T14:49:09.104759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:43.144454Z","iopub.execute_input":"2022-12-01T15:53:43.144801Z","iopub.status.idle":"2022-12-01T15:53:53.120512Z","shell.execute_reply.started":"2022-12-01T15:53:43.144768Z","shell.execute_reply":"2022-12-01T15:53:53.119241Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/25 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53ef5b15949478f80084662b9be70bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829e9731028e40eeaadc5b3d2126cd87"}},"metadata":{}}]},{"cell_type":"code","source":"def train_logreg(batch_size, train_feats_data, test_feats_data, model_suffix, max_epochs=100, **kwargs):\n    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n                         devices=1,\n                         max_epochs=max_epochs,\n                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc'),\n                                    LearningRateMonitor(\"epoch\")],\n                         enable_progress_bar=False,\n                         check_val_every_n_epoch=10)\n    trainer.logger._default_hp_metric = None\n    # Data loaders\n    train_loader = data.DataLoader(train_feats_data, batch_size=batch_size, shuffle=True, \n                                   drop_last=False, pin_memory=True, num_workers=0)\n    test_loader = data.DataLoader(test_feats_data, batch_size=batch_size, shuffle=False, \n                                  drop_last=False, pin_memory=True, num_workers=0)\n\n    # Check whether pretrained model exists. If yes, load it and skip training\n    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"LogisticRegression_{model_suffix}.ckpt\")\n    if os.path.isfile(pretrained_filename):\n        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n        model = LogisticRegression.load_from_checkpoint(pretrained_filename)\n    else:\n        pl.seed_everything(42)  # To be reproducable\n        model = LogisticRegression(**kwargs)\n        trainer.fit(model, train_loader, test_loader)\n        model = LogisticRegression.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n    return trainer,model#, result","metadata":{"id":"ZbG6DhsixJxd","papermill":{"duration":0.023453,"end_time":"2022-11-19T14:49:09.234406","exception":false,"start_time":"2022-11-19T14:49:09.210953","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:53.122849Z","iopub.execute_input":"2022-12-01T15:53:53.123295Z","iopub.status.idle":"2022-12-01T15:53:53.134590Z","shell.execute_reply.started":"2022-12-01T15:53:53.123253Z","shell.execute_reply":"2022-12-01T15:53:53.133549Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"results = {}\ntrainer,model = train_logreg(batch_size=64,\n                                    train_feats_data=train_feats_simclr,\n                                    test_feats_data=test_feats_simclr,\n                                    model_suffix=\"any\",\n                                    feature_dim=train_feats_simclr.tensors[0].shape[1],\n                                    num_classes=3,\n                                    lr=1e-3,\n                                    weight_decay=1e-3)\n    ","metadata":{"id":"4K83d43ExJxe","outputId":"30abda61-d352-4bf8-9118-159dd5bfc25a","papermill":{"duration":0.022889,"end_time":"2022-11-19T14:49:09.373237","exception":false,"start_time":"2022-11-19T14:49:09.350348","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-12-01T15:53:53.136318Z","iopub.execute_input":"2022-12-01T15:53:53.136690Z","iopub.status.idle":"2022-12-01T15:54:08.984557Z","shell.execute_reply.started":"2022-12-01T15:53:53.136651Z","shell.execute_reply":"2022-12-01T15:54:08.983598Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1896: PossibleUserWarning: The number of training batches (25) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n  category=PossibleUserWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"test_loader = data.DataLoader(test_feats_simclr, batch_size=1, shuffle=False, \n                                  drop_last=False, pin_memory=True, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:54:08.986163Z","iopub.execute_input":"2022-12-01T15:54:08.986520Z","iopub.status.idle":"2022-12-01T15:54:08.993629Z","shell.execute_reply.started":"2022-12-01T15:54:08.986478Z","shell.execute_reply":"2022-12-01T15:54:08.991919Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"preds = list()\nlabels = list()\nfor i in test_loader:\n    preds.append(model.forward(i[0]))\n    labels.append(i[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:54:08.995026Z","iopub.execute_input":"2022-12-01T15:54:08.995558Z","iopub.status.idle":"2022-12-01T15:54:09.095802Z","shell.execute_reply.started":"2022-12-01T15:54:08.995521Z","shell.execute_reply":"2022-12-01T15:54:09.094972Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import numpy as np\npred_argmax = [np.argmax(list(p.detach().cpu().numpy()[0])) for p in preds]\nlabels_argmax = [l.detach().cpu().numpy()[0] for l in labels]","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:54:09.097201Z","iopub.execute_input":"2022-12-01T15:54:09.097560Z","iopub.status.idle":"2022-12-01T15:54:09.109706Z","shell.execute_reply.started":"2022-12-01T15:54:09.097526Z","shell.execute_reply":"2022-12-01T15:54:09.108638Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nclassification_report(pred_argmax,labels_argmax).split(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:54:09.110934Z","iopub.execute_input":"2022-12-01T15:54:09.111361Z","iopub.status.idle":"2022-12-01T15:54:09.125708Z","shell.execute_reply.started":"2022-12-01T15:54:09.111323Z","shell.execute_reply":"2022-12-01T15:54:09.124776Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"['              precision    recall  f1-score   support',\n '',\n '           0       0.91      0.89      0.90       133',\n '           1       0.80      0.80      0.80       130',\n '           2       0.76      0.78      0.77       127',\n '',\n '    accuracy                           0.82       390',\n '   macro avg       0.82      0.82      0.82       390',\n 'weighted avg       0.82      0.82      0.82       390',\n '']"},"metadata":{}}]},{"cell_type":"markdown","source":"# Resnet fine tune","metadata":{}},{"cell_type":"code","source":"def get_net():\n    resnet = torchvision.models.resnet34(pretrained=True)\n    \n    # Substitute the FC output layer\n    resnet.fc = torch.nn.Linear(resnet.fc.in_features, 10)\n    torch.nn.init.xavier_uniform_(resnet.fc.weight)\n    return resnet\n\n\nimport time\n\ndef train(net, train_dataloader, valid_dataloader, criterion, optimizer, scheduler=None, epochs=10, device='cpu', checkpoint_epochs=10):\n    start = time.time()\n    print(f'Training for {epochs} epochs on {device}')\n    \n    for epoch in range(1,epochs+1):\n        print(f\"Epoch {epoch}/{epochs}\")\n        \n        net.train()  # put network in train mode for Dropout and Batch Normalization\n        train_loss = torch.tensor(0., device=device)  # loss and accuracy tensors are on the GPU to avoid data transfers\n        train_accuracy = torch.tensor(0., device=device)\n        for X, y in train_dataloader:\n            X = X.to(device)\n            y = y.to(device)\n            preds = net(X)\n            loss = criterion(preds, y)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            with torch.no_grad():\n                train_loss += loss * train_dataloader.batch_size\n                train_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n        \n        if valid_dataloader is not None:\n            net.eval()  # put network in train mode for Dropout and Batch Normalization\n            valid_loss = torch.tensor(0., device=device)\n            valid_accuracy = torch.tensor(0., device=device)\n            with torch.no_grad():\n                for X, y in valid_dataloader:\n                    X = X.to(device)\n                    y = y.to(device)\n                    preds = net(X)\n                    loss = criterion(preds, y)\n\n                    valid_loss += loss * valid_dataloader.batch_size\n                    valid_accuracy += (torch.argmax(preds, dim=1) == y).sum()\n        \n        if scheduler is not None: \n            scheduler.step()\n            \n        print(f'Training loss: {train_loss/len(train_dataloader.dataset):.2f}')\n        print(f'Training accuracy: {100*train_accuracy/len(train_dataloader.dataset):.2f}')\n        \n        if valid_dataloader is not None:\n            print(f'Valid loss: {valid_loss/len(valid_dataloader.dataset):.2f}')\n            print(f'Valid accuracy: {100*valid_accuracy/len(valid_dataloader.dataset):.2f}')\n        \n        if epoch%checkpoint_epochs==0:\n            torch.save({\n                'epoch': epoch,\n                'state_dict': net.state_dict(),\n                'optimizer': optimizer.state_dict(),\n            }, './checkpoint.pth.tar')\n        \n        print()\n        \n        if (100*train_accuracy/len(train_dataloader.dataset))>97:\n            break\n    end = time.time()\n    print(f'Total training time: {end-start:.1f} seconds')\n    return net\n\ntrain_img_aug_data = SDSSDataset(\"./balanced_train.csv\",\"./balanced_images\")\ntest_img_aug_data = SDSSDataset(\"./balanced_test.csv\",\"./balanced_images\")\ntrain_loader = data.DataLoader(train_img_aug_data, batch_size=64, shuffle=True, \n                               drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)\ntest_loader = data.DataLoader(test_img_data, batch_size=64, shuffle=False, \n                              drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nlr, weight_decay, epochs = 1e-5, 5e-4, 20\n\nnet = get_net().to(device)\n\n# Standard CrossEntropy Loss for multi-class classification problems\ncriterion = torch.nn.CrossEntropyLoss()\n\n# params_1x are the parameters of the network body, i.e., of all layers except the FC layers\nparams_1x = [param for name, param in net.named_parameters() if 'fc' not in str(name)]\noptimizer = torch.optim.Adam([{'params':params_1x}, {'params': net.fc.parameters(), 'lr': lr*10}], lr=lr, weight_decay=weight_decay)\n\nnet = train(net, train_loader, test_loader, criterion, optimizer, None, epochs, device)","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:04:04.086002Z","iopub.execute_input":"2022-12-01T16:04:04.086409Z","iopub.status.idle":"2022-12-01T16:04:32.766233Z","shell.execute_reply.started":"2022-12-01T16:04:04.086378Z","shell.execute_reply":"2022-12-01T16:04:32.764275Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"   class           image\n0      2  image_7444.jpg\n1      0  image_1163.jpg\n   class           image\n0      1  image_0846.jpg\n1      0  image_9084.jpg\nTraining for 20 epochs on cuda\nEpoch 1/20\nTraining loss: 2.31\nTraining accuracy: 33.72\nValid loss: 1.96\nValid accuracy: 39.74\n\nEpoch 2/20\nTraining loss: 0.91\nTraining accuracy: 68.33\nValid loss: 1.67\nValid accuracy: 46.92\n\nEpoch 3/20\nTraining loss: 0.52\nTraining accuracy: 81.09\nValid loss: 1.56\nValid accuracy: 47.95\n\nEpoch 4/20\nTraining loss: 0.32\nTraining accuracy: 87.82\nValid loss: 1.53\nValid accuracy: 51.28\n\nEpoch 5/20\nTraining loss: 0.23\nTraining accuracy: 91.47\nValid loss: 1.53\nValid accuracy: 50.26\n\nEpoch 6/20\nTraining loss: 0.18\nTraining accuracy: 94.42\nValid loss: 1.55\nValid accuracy: 49.23\n\nEpoch 7/20\nTraining loss: 0.15\nTraining accuracy: 94.81\nValid loss: 1.51\nValid accuracy: 50.00\n\nEpoch 8/20\nTraining loss: 0.12\nTraining accuracy: 96.15\nValid loss: 1.55\nValid accuracy: 50.00\n\nEpoch 9/20\nTraining loss: 0.09\nTraining accuracy: 97.05\nValid loss: 1.50\nValid accuracy: 50.00\n\nTotal training time: 28.2 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"net.eval()\nlabels = []\ntestlabels = []\ntest_loader = data.DataLoader(test_img_aug_data, batch_size=1, shuffle=False, \n                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\nfor inputs,labels1 in tqdm(test_loader):\n    inputs = inputs.to(device)\n    testlabels.append(labels1.detach().cpu().numpy()[0])\n    labels1 = torch.tensor(labels1).to(device)\n    outputs = net(inputs)\n    _, predictions = torch.max(outputs, 1)\n    predictions = predictions.to(\"cpu\")\n    labels.extend(predictions.numpy())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:04:32.770721Z","iopub.execute_input":"2022-12-01T16:04:32.771976Z","iopub.status.idle":"2022-12-01T16:04:39.149324Z","shell.execute_reply.started":"2022-12-01T16:04:32.771919Z","shell.execute_reply":"2022-12-01T16:04:39.148194Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7333f92f7545405e9b2321cad65ddf19"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if __name__ == \"__main__\":\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.metrics import classification_report\nclassification_report(testlabels,labels).split(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:04:39.151363Z","iopub.execute_input":"2022-12-01T16:04:39.152062Z","iopub.status.idle":"2022-12-01T16:04:39.165310Z","shell.execute_reply.started":"2022-12-01T16:04:39.152018Z","shell.execute_reply":"2022-12-01T16:04:39.164188Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"['              precision    recall  f1-score   support',\n '',\n '           0       0.86      0.88      0.87       130',\n '           1       0.69      0.65      0.67       130',\n '           2       0.68      0.69      0.69       130',\n '',\n '    accuracy                           0.74       390',\n '   macro avg       0.74      0.74      0.74       390',\n 'weighted avg       0.74      0.74      0.74       390',\n '']"},"metadata":{}}]},{"cell_type":"code","source":"torch.save(net.state_dict(),\"./resnet_finetune.pth\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:06:30.725302Z","iopub.execute_input":"2022-12-01T16:06:30.725672Z","iopub.status.idle":"2022-12-01T16:06:30.882044Z","shell.execute_reply.started":"2022-12-01T16:06:30.725641Z","shell.execute_reply":"2022-12-01T16:06:30.881059Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"# Resnet scratch","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset,DataLoader\nfrom torchvision import transforms,models\nfrom tqdm import tqdm_notebook as tqdm\n\nclass ResidualBlock(nn.Module):\n    def __init__(self,in_channels,out_channels,stride=1,kernel_size=3,padding=1,bias=False):\n        super(ResidualBlock,self).__init__()\n        self.cnn1 =nn.Sequential(\n            nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(True)\n        )\n        self.cnn2 = nn.Sequential(\n            nn.Conv2d(out_channels,out_channels,kernel_size,1,padding,bias=False),\n            nn.BatchNorm2d(out_channels)\n        )\n        if stride != 1 or in_channels != out_channels:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n        else:\n            self.shortcut = nn.Sequential()\n            \n    def forward(self,x):\n        residual = x\n        x = self.cnn1(x)\n        x = self.cnn2(x)\n        x += self.shortcut(residual)\n        x = nn.ReLU(True)(x)\n        return x\n    \n\nclass ResNet18(nn.Module):\n    def __init__(self):\n        super(ResNet18,self).__init__()\n        \n        self.block1 = nn.Sequential(\n            nn.Conv2d(3,64,kernel_size=2,stride=2,padding=3,bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True)\n        )\n        \n        self.block2 = nn.Sequential(\n            nn.MaxPool2d(1,1),\n            ResidualBlock(64,64),\n            ResidualBlock(64,64,2)\n        )\n        \n        self.block3 = nn.Sequential(\n            ResidualBlock(64,128),\n            ResidualBlock(128,128,2)\n        )\n        \n        self.block4 = nn.Sequential(\n            ResidualBlock(128,256),\n            ResidualBlock(256,256,2)\n        )\n        self.block5 = nn.Sequential(\n            ResidualBlock(256,512),\n            ResidualBlock(512,512,2)\n        )\n        \n        self.avgpool = nn.AvgPool2d(2)\n        # vowel_diacritic\n        self.fc1 = nn.Linear(512,3)\n        \n    def forward(self,x):\n        x = self.block1(x)\n        x = self.block2(x)\n        x = self.block3(x)\n        x = self.block4(x)\n        x = self.block5(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0),-1)\n        x1 = self.fc1(x)\n        return x1\n    \ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:59:38.469280Z","iopub.execute_input":"2022-12-01T15:59:38.469861Z","iopub.status.idle":"2022-12-01T15:59:38.486951Z","shell.execute_reply.started":"2022-12-01T15:59:38.469817Z","shell.execute_reply":"2022-12-01T15:59:38.485830Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch.nn.functional as nnf\nfrom torch.utils.data.dataset import Dataset\nfrom skimage import io as skio\nfrom skimage import transform\nfrom torchvision import transforms as T\n\nclass SDSSDataset(Dataset):\n    \"\"\"Face Landmarks dataset.\"\"\"\n\n    def __init__(self, csv_file, root_dir):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.df = pd.read_csv(csv_file)\n        label_dict = {'GALAXY':0,'STAR':1,'QSO':2}\n        self.df['class'] = self.df['class'].apply(lambda x : label_dict[x])\n        print(self.df.head(2))\n        self.root_dir = root_dir\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.root_dir,self.df.iloc[idx][\"image\"])\n        image = skio.imread(img_name).reshape(3,128,128).astype(np.float32)\n        torch_tensor = torch.from_numpy(image).unsqueeze(0)\n        \n        out = nnf.interpolate(torch_tensor, size=(64, 64), mode='nearest').squeeze(0)\n        \n        image = out.cpu().detach().numpy().reshape(3,64,64)\n#         print(image.shape)\n        label = self.df.iloc[idx][\"class\"]\n        return image,label\ntrain_img_aug_data = SDSSDataset(\"./balanced_train.csv\",\"./balanced_images\")\ntest_img_aug_data = SDSSDataset(\"./balanced_test.csv\",\"./balanced_images\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:59:38.488634Z","iopub.execute_input":"2022-12-01T15:59:38.489070Z","iopub.status.idle":"2022-12-01T15:59:38.516593Z","shell.execute_reply.started":"2022-12-01T15:59:38.489032Z","shell.execute_reply":"2022-12-01T15:59:38.515522Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"   class           image\n0      2  image_7444.jpg\n1      0  image_1163.jpg\n   class           image\n0      1  image_0846.jpg\n1      0  image_9084.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"model = ResNet18().to(device)\noptimizer = optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.05)\ncriterion = nn.CrossEntropyLoss()\nbatch_size=32\nepochs = 12 # original 50\nmodel.train()\nlosses = []\naccs = []\nfor epoch in range(epochs):\n    train_loader = data.DataLoader(train_img_aug_data, batch_size=batch_size, shuffle=True, \n                                   drop_last=True, pin_memory=True, num_workers=NUM_WORKERS)\n    test_loader = data.DataLoader(test_img_data, batch_size=batch_size, shuffle=False, \n                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\n    \n    print('epochs {}/{} '.format(epoch+1,epochs))\n    running_loss = 0.0\n    running_acc = 0.0\n    for idx, (inputs,labels1) in tqdm(enumerate(train_loader),total=len(train_loader)):\n        inputs = inputs.to(device)\n        labels = torch.tensor(labels1).to(device)\n        \n        optimizer.zero_grad()\n        outputs1 = model(inputs.float())\n        loss1 = criterion(outputs1.to(device),labels1.to(device))\n        \n        running_loss = loss1\n        running_acc = (outputs1.argmax(1).to(device)==labels1.to(device)).float().mean()\n        \n        loss1.backward()\n        optimizer.step()\n    #scheduler.step()\n    losses.append(running_loss/len(train_loader))\n    accs.append(running_acc/(len(train_loader)))\n    print('acc : {:.2f}%'.format(running_acc))\n    \n    print('loss : {:.4f}'.format(running_loss))\n    if running_acc>0.98:\n        break\ntorch.save(model.state_dict(), 'resnet34_50epochs_saved_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2022-12-01T15:59:38.519200Z","iopub.execute_input":"2022-12-01T15:59:38.519854Z","iopub.status.idle":"2022-12-01T16:00:06.976579Z","shell.execute_reply.started":"2022-12-01T15:59:38.519819Z","shell.execute_reply":"2022-12-01T16:00:06.975309Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"epochs 1/12 \n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9096ec8bff743caa614bcccdcd131f8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","output_type":"stream"},{"name":"stdout","text":"acc : 0.91%\nloss : 0.3475\nepochs 2/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c764c1222c04742bfbd0df6fd045ec4"}},"metadata":{}},{"name":"stdout","text":"acc : 0.91%\nloss : 0.2699\nepochs 3/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc05395295f4aedac2c33a51c2c505c"}},"metadata":{}},{"name":"stdout","text":"acc : 0.81%\nloss : 0.4420\nepochs 4/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73b79362b0ae4b3faa0ebb7a3fa81050"}},"metadata":{}},{"name":"stdout","text":"acc : 0.81%\nloss : 0.3454\nepochs 5/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62548333aef34abc9a98d1121f09f04a"}},"metadata":{}},{"name":"stdout","text":"acc : 0.88%\nloss : 0.5048\nepochs 6/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf41461fb43c4a7a88bee2f92425a75f"}},"metadata":{}},{"name":"stdout","text":"acc : 0.84%\nloss : 0.4737\nepochs 7/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bea24ac4752a4614bfa37ac5e6d65e68"}},"metadata":{}},{"name":"stdout","text":"acc : 0.88%\nloss : 0.4554\nepochs 8/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9177e33d3876406bba13c3b821f5e3e4"}},"metadata":{}},{"name":"stdout","text":"acc : 0.97%\nloss : 0.0425\nepochs 9/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b4f8d9a77b43f8b59e4c09d911a059"}},"metadata":{}},{"name":"stdout","text":"acc : 0.91%\nloss : 0.1662\nepochs 10/12 \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/48 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e67502aafed24c25b6e6452b85f83b0f"}},"metadata":{}},{"name":"stdout","text":"acc : 1.00%\nloss : 0.0193\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.load_state_dict(torch.load('resnet34_50epochs_saved_weights.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:00:06.978426Z","iopub.execute_input":"2022-12-01T16:00:06.979183Z","iopub.status.idle":"2022-12-01T16:00:07.044412Z","shell.execute_reply.started":"2022-12-01T16:00:06.979137Z","shell.execute_reply":"2022-12-01T16:00:07.043281Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\nlabels = []\ntestlabels = []\ntest_loader = data.DataLoader(test_img_aug_data, batch_size=1, shuffle=False, \n                                  drop_last=False, pin_memory=True, num_workers=NUM_WORKERS)\nfor inputs,labels1 in tqdm(test_loader):\n    inputs = inputs.to(device)\n    testlabels.append(labels1.detach().cpu().numpy()[0])\n    labels1 = torch.tensor(labels1).to(device)\n    outputs = model(inputs)\n    _, predictions = torch.max(outputs, 1)\n    predictions = predictions.to(\"cpu\")\n    labels.extend(predictions.numpy())\n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:00:07.046657Z","iopub.execute_input":"2022-12-01T16:00:07.047045Z","iopub.status.idle":"2022-12-01T16:00:11.699995Z","shell.execute_reply.started":"2022-12-01T16:00:07.047009Z","shell.execute_reply":"2022-12-01T16:00:11.698862Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\nPlease use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n  \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/390 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f74e651fcbe647db81554f840ab1df6b"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if __name__ == \"__main__\":\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.metrics import classification_report\nclassification_report(testlabels,labels).split(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-12-01T16:00:11.701958Z","iopub.execute_input":"2022-12-01T16:00:11.702622Z","iopub.status.idle":"2022-12-01T16:00:11.718508Z","shell.execute_reply.started":"2022-12-01T16:00:11.702579Z","shell.execute_reply":"2022-12-01T16:00:11.717498Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"['              precision    recall  f1-score   support',\n '',\n '           0       0.97      0.92      0.94       130',\n '           1       0.97      0.74      0.84       130',\n '           2       0.75      0.97      0.85       130',\n '',\n '    accuracy                           0.87       390',\n '   macro avg       0.90      0.87      0.87       390',\n 'weighted avg       0.90      0.87      0.87       390',\n '']"},"metadata":{}}]}]}